# 主数据源，默认的
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://192.168.8.115:15001/schoolface
spring.datasource.username=bjyf
spring.datasource.password=bjyf@server
# 其他数据源
#spring.datasource.db2.driverClassName=com.mysql.jdbc.Driver
#spring.datasource.db2.url=jdbc:mysql://192.168.8.115:15001/schooldata
#spring.datasource.db2.username=bjyf
#spring.datasource.db2.password=bjyf@server
# 下面为连接池的补充设置，应用到上面所有数据源中
# 初始化大小，最小，最大
spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=SELECT 1 FROMDUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.poolPreparedStatements=true
spring.datasource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
# 合并多个DruidDataSource的监控数据
#spring.datasource.useGlobalDataSourceStat=true

#rabbitmq配置
spring.rabbitmq.host=192.168.8.148
spring.rabbitmq.port=15005
spring.rabbitmq.username=ganinfo
spring.rabbitmq.password=ganinfop@55

#使用单个redis=redis，redis集群=redisCluster
srping.redis.type=redis
#单个redis

spring.redis.host=192.168.8.148
spring.redis.port=15020
spring.redis.password=ganinfo
#spring.redis.host=192.168.2.243
#spring.redis.port=6379
#spring.redis.password=ganinfo
#可用连接实例的最大数目，默认值为8；
#如果赋值为-1，则表示不限制；如果pool已经分配了maxActive个jedis实例，则此时pool的状态为exhausted(耗尽)。
spring.redis.maxActive=1000
# 控制一个pool最多有多少个状态为idle(空闲的)的jedis实例，默认值也是8。
spring.redis.maxIdle=20
#等待可用连接的最大时间，单位毫秒，默认值为-1，表示永不超时。如果超过等待时间，则直接抛出JedisConnectionException；
spring.redis.maxWait=10000
#在borrow一个jedis实例时，是否提前进行validate操作；如果为true，则得到的jedis实例均是可用的；
spring.redis.testOnBorrow=true
spring.redis.testOnReturn=true
spring.redis.timeOut=3000
#redis超时时间 1*1*60*60
spring.redis.redisExpire=3600


#redis集群配置
spring.redis.pool.nodes=172.16.200.218:6379,172.16.200.218:6379
spring.redis.pool.timeOut=3000
#返回值的超时时间
spring.redis.pool.soTimeOut=5000
spring.redis.pool.maxActive=1024
spring.redis.pool.maxIdle=200
spring.redis.pool.maxWait=10000
spring.redis.pool.maxAttempts=5
spring.redis.pool.testOnBorrow=true
spring.redis.pool.password=ganinfo
spring.redis.pool.expireSeconds=3600


#activemq配置
activemq.username=admin
activemq.password=admin
#activemq.url=tcp://172.16.1.28:61616
activemq.url=tcp://223.223.176.210:61616

#定义各种额外的详情给服务端显示
#从pom.xml中获取
info.app.name="@project.name@"
info.app.description="@project.description@"
info.app.version="@project.version@"
info.spring-boot-version="@project.parent.version@"
info.version=@project.version@


#服务心跳上报地址
monitor.up.url=http://192.168.2.59:8080/maintenance/heart/send

#mongo连接地址
spring.data.mongodb.uri=mongodb://192.168.2.239:27017/analyze

#activemq
spring.activemq.broker-url=tcp://223.223.176.210:6161
spring.activemq.user=admin
spring.activemq.password=admin
config.activemq.queue=devicewarn_push

#图片地址
file.imgFilePath=D:\\
file.path=snapPhoto

#设备推送配置
facerecognite.push.ip=10.1.201.121
facerecognite.push.port=8080
facerecognite.push.url=command/warninglog/alarmLog

spring.hadoop.paths=10.12.20.130:9000,10.12.20.131:9000
#文件保存路径
file.save.path=D:/fileupload
#base64图片保存路径
img.save.path=D:/fileupload

#人脸检测配置
face.WIN_APP_ID=nUMgqYx9R36xof5k2VDPiqcs14L3qj6cRpcFYdDiUXa
face.WIN_FD_SDKKEY=D6rVNDznPZwHmmo2r97iEtB89QvBSMkQ1ZZ1pR23sLs9
face.LINUX_APP_ID=nUMgqYx9R36xof5k2VDPiqk2QKXpoZ2RyC6Ye8T5AVJ
face.LINUX_FD_SDKKEY=8XcqQMTPuWLwYmMNCjnEPY8RuGaxpn3idwR96CnqahP
#ES配置加检验
spring.data.elasticsearch.clustername=test-cluster
spring.data.elasticsearch.ip=192.168.8.120,192.168.8.121,192.168.8.122
spring.data.elasticsearch.port=15032
spring.data.elasticsearch.username=elastic
spring.data.elasticsearch.password=ganinfo
#邮箱工具配置
mail_host=smtp.126.com
mail_from=ganinfo@126.com
mail_username=ganinfo@126.com
mail_password=ganinfo2017

##kafka-consummer
#kafka-服务地址
spring.kafka.consumer.bootstrap-servers=192.168.8.30:15007
#kafka-消费者组
spring.kafka.consumer.group-id=student_backbed
#Kafka-是否开启自动提交offset
spring.kafka.consumer.enable-auto-commit=true
#kafka-自动提交间隔
spring.kafka.consumer.auto-commit-interval=200
#kafka-序列化方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#kafka-一次最多拉取数据量
spring.kafka.consumer.max-poll-records=1
# earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
# latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
# none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=earliest